{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71bf2474",
   "metadata": {},
   "source": [
    "# Dissecting Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7904e1",
   "metadata": {},
   "source": [
    "The first step for us is to run `python3 data/nlab/prepare.py` after having cloned the `nlab-content` submodule. This will create a file `data/nlab/input.md` of roughly 91 MiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e1b229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95159406\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/nlab/input.md\", \"r\", encoding=\"utf-8\") as fd:\n",
    "    text = fd.read()\n",
    "\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ef360d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ §¨«­¯°²³´µ·¹»ÀÁÄÅÆÉÎÓÖ×ØÜßàáâãäåæçèéêëìíîïñòóôöøùúûüýĀāăąĆćĈČčđĕęěğīĭİıķŁłńōőŒœŗřŚśŝŞşŠšţťūűŻżŽžſșțȩɐɪʰʲʹʼˆˈ̧̣̀́̂̃̄̈̌͡ΑΒΓΔΕΘΛΜΠΣΦΨΩάέήίαβγδεζηθικλμνξοπρςστυφχψωόύϑϒϕϖϵАБВГДЕЖЗИКЛМНОПРСТУФХШЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёіћᵒᵖᵢᶜṣṬỳἀἐἓἕἢἣἰὁὄὅὐὑὗὰὲὴὶὸῃῆῇῖῦῶῷ ​‌‍‎‐‑–—‘’“”„†•…  ′⁻ⁿ₀₁₂₄₆₇₈₉ℂℋℓ№ℚℤΩℵ⅋Ⅱ←→↦⇓⇔⇸∀∂∈−∗√∞∧∼≅≈≠≡≤≥≺⊂⊗⋮─◦♧♭✄【】のオダネノブヨ下五何信分夫学山幾式引形微德徹志数方李村田程空米系經经群蕉论谷豊辻道郎间香ﬀﬁﬂﬃ\n",
      "479\n"
     ]
    }
   ],
   "source": [
    "vocab = list(sorted(list(set(text))))\n",
    "vocab_size = len(vocab)\n",
    "print(\"\".join(vocab))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "301f7ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 13, 15, 15, 2, 93, 28, 2, 16, 84, 75, 73, 74, 86, 42, 67, 80, 70, 53, 75, 70, 71, 95, 1, 13, 15, 15, 2, 93, 28, 2, 16, 86, 81, 69, 2, 16, 69, 78, 75, 69, 77, 38, 81, 89, 80, 2, 86, 67, 68]\n"
     ]
    }
   ],
   "source": [
    "# import tiktoken\n",
    "\n",
    "# enc = tiktoken.get_encoding(\"gpt2\")\n",
    "# enc.n_vocab\n",
    "# t = enc.encode(text[:50])\n",
    "# print(t)\n",
    "# print(enc.decode(t))\n",
    "ctoi = {ch: i for i, ch in enumerate(vocab)}\n",
    "itoc = {i: ch for i, ch in enumerate(vocab)}\n",
    "\n",
    "encode = lambda s: [ctoi[c] for c in s]\n",
    "decode = lambda v: \"\".join([itoc[i] for i in v])\n",
    "\n",
    "print(encode(text[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "578261f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95159406]) torch.int64\n",
      "tensor([ 1, 13, 15, 15,  2, 93, 28,  2, 16, 84, 75, 73, 74, 86, 42, 67, 80, 70,\n",
      "        53, 75, 70, 71, 95,  1, 13, 15, 15,  2, 93, 28,  2, 16, 86, 81, 69,  2,\n",
      "        16, 69, 78, 75, 69, 77, 38, 81, 89, 80,  2, 86, 67, 68, 75, 80, 70, 71,\n",
      "        90, 31,  4, 18,  4, 95,  1,  5,  5,  5,  2, 37, 81, 80, 86, 71, 90, 86,\n",
      "         1,  5,  5,  5,  5,  2, 50, 74, 75, 78, 81, 85, 81, 82, 74, 91,  1, 13,\n",
      "        15, 15,  2, 93, 28,  2, 16, 74, 75, 70, 71, 95,  1, 61, 61,  3, 75, 80,\n",
      "        69, 78, 87, 70, 71,  2, 82, 74, 75, 78, 81, 85, 81, 82, 74, 91,  2, 15,\n",
      "         2, 69, 81, 80, 86, 71, 80, 86, 85, 63, 63,  1, 31, 15, 15,  1, 31, 15,\n",
      "        15,  1, 31, 15, 15,  1,  1,  5, 37, 81, 80, 86, 71, 80, 86, 85,  5,  1,\n",
      "        12,  2, 86, 67, 68, 78, 71,  2, 81, 72,  2, 69, 81, 80, 86, 71, 80, 86,\n",
      "        85,  1, 93, 28, 86, 81, 69, 95,  1,  1,  5,  5,  2, 43, 70, 71, 67,  1,\n",
      "         1, 10, 16, 16, 16, 11,  1,  1, 35,  2, 82, 81, 75, 80, 86,  2, 81, 72,\n",
      "         2, 88, 75, 71, 89,  2, 75, 80,  2, 61, 61, 82, 74, 75, 78, 81, 85, 81,\n",
      "        82, 74, 91, 63, 63, 16,  1,  1, 10, 16, 16, 16, 11,  1,  1, 35,  2, 82,\n",
      "        84, 81, 79, 75, 80, 71, 80, 86,  2, 71, 90, 67, 79, 82, 78, 71,  2, 75,\n",
      "        85,  2, 61, 61, 41, 71, 81, 84, 73,  2, 42, 71, 73, 71, 78, 63, 63,  9,\n",
      "        85,  2, 61, 61, 80, 67, 86, 87, 84, 67, 78,  2, 82, 74, 75, 78, 81, 85,\n",
      "        81, 82, 74, 91, 63, 63,  2, 67, 85,  2, 71, 90, 82, 84, 71, 85, 85, 71,\n",
      "        70,  2, 75, 80,  2, 74, 75, 85,  2, 65, 61, 61, 53, 69, 75, 71, 80, 69,\n",
      "        71,  2, 81, 72,  2, 46, 81, 73, 75, 69, 63, 63, 65, 16,  2, 43, 80,  2,\n",
      "        81, 82, 82, 81, 85, 75, 86, 75, 81, 80,  2, 86, 81,  2, 86, 74, 75, 85,\n",
      "         2, 75, 85,  2, 86, 74, 71,  2, 85, 69, 74, 81, 81, 78,  2, 81, 72,  2,\n",
      "        61, 61, 67, 80, 67, 78, 91, 86, 75, 69,  2, 82, 74, 75, 78, 81, 85, 81,\n",
      "        82, 74, 91, 63, 63,  2, 89, 74, 75, 69, 74,  2, 67, 75, 79, 85,  2, 86,\n",
      "        81,  2, 79, 67, 77, 71,  2, 87, 85, 71,  2, 81, 72,  2, 72, 81, 84, 79,\n",
      "        67, 78,  2, 84, 71, 67, 85, 81, 80, 75, 80, 73,  2, 75, 80,  2, 61, 61,\n",
      "        72, 75, 84, 85, 86, 15, 81, 84, 70, 71, 84,  2, 78, 81, 73, 75, 69, 63,\n",
      "        63, 16,  2, 42, 81, 89, 71, 88, 71, 84,  2, 61, 61, 57, 75, 78, 78, 75,\n",
      "        67, 79,  2, 46, 67, 89, 88, 71, 84, 71, 63, 63,  2, 67, 84, 73, 87, 71,\n",
      "        70,  2, 86, 74, 67, 86,  2, 77, 71, 91,  2, 42, 71, 73, 71, 78, 75, 67,\n",
      "        80,  2, 69, 81, 80, 69, 71, 82, 86, 85,  2, 85, 87, 69, 74,  2, 67, 85,\n",
      "         2, 65, 61, 61, 87, 80, 75, 86, 91,  2, 81, 72,  2, 81, 82, 82, 81, 85,\n",
      "        75, 86, 71, 85, 63, 63, 65, 14,  2, 65, 61, 61, 35, 87, 72, 74, 71, 68,\n",
      "        87, 80, 73, 63, 63, 65, 14,  2, 65, 61, 61, 69, 67, 86, 71, 73, 81, 84,\n",
      "        91,  2, 81, 72,  2, 68, 71, 75, 80, 73, 63, 63, 65, 14,  2, 70, 81,  2,\n",
      "        74, 67, 88, 71,  2, 87, 85, 71, 72, 87, 78,  2, 72, 81, 84, 79, 67, 78,\n",
      "        75, 92, 67, 86, 75, 81, 80,  2, 75, 80,  2, 61, 61, 79, 81, 70, 67, 78,\n",
      "         2, 86, 91, 82, 71,  2, 86, 74, 71, 81, 84, 91, 63, 63,  2, 10, 81, 84,\n",
      "         2, 75, 86, 85,  2, 61, 61, 69, 67, 86, 71, 73, 81, 84, 75, 69, 67, 78,\n",
      "         2, 85, 71, 79, 67, 80, 86, 75, 69, 85, 63, 63, 11, 16,  1,  1,  1,  5,\n",
      "         5,  2, 52, 71, 78, 67, 86, 75, 81, 80,  2, 86, 81,  2, 82, 74, 91, 85,\n",
      "        75, 69, 85,  1,  1, 32,  2, 54, 74, 71, 84, 71,  2, 67, 84, 71,  2, 83,\n",
      "        87, 75, 86, 71,  2, 67,  2, 72, 71, 89,  2, 85, 86, 71, 82, 85,  2, 68,\n",
      "        71, 86, 89, 71, 71, 80,  2, 67, 80,  2, 71, 79, 82, 75, 84, 75, 69, 75,\n",
      "        85, 86,  2, 67, 80, 70,  2, 67,  2, 42, 71, 73, 71, 78, 75, 67, 80,  2,\n",
      "        10, 81, 84,  2, 81, 68, 76, 71, 69, 86, 75, 88, 71,  2, 75, 70, 71, 67,\n",
      "        78, 75, 85, 86, 11, 16,  2, 54, 74, 71,  2, 72, 81, 84, 79, 71, 84,  9,\n",
      "        85,  2, 88, 75, 71, 89,  2, 81, 72,  2, 85, 69, 75, 71, 80, 86, 75, 72,\n",
      "        75, 69,  2, 61, 61, 86, 74, 71, 81, 84, 91,  2, 10, 82, 74, 91, 85, 75,\n",
      "        69, 85, 11, 94, 86, 74, 71, 81, 84, 91, 63, 63,  2, 73, 71, 80, 71, 84,\n",
      "        67, 78, 78, 91,  2, 75, 85,  2, 86, 74, 67, 86,  2, 75, 86,  9, 85,  2,\n",
      "        67, 80,  2, 71, 72, 72, 75, 69, 75, 71, 80, 86,  2, 71, 80, 69, 81, 70,\n",
      "        75, 80, 73,  2, 81, 72,  2, 86, 74, 71,  2, 61, 61, 81, 68, 85, 71, 84,\n",
      "        88, 67, 86, 75, 81, 80, 85, 63, 63,  2, 89, 71,  2, 79, 67, 77, 71,  2,\n",
      "        81, 72,  2, 86, 74, 71,  2, 89, 81, 84, 78, 70, 14,  2, 67, 69, 69, 81,\n",
      "        79, 82, 67, 80, 75, 71, 70,  2, 86, 91], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long, device=\"cuda\")\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b305a7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85643465]) torch.Size([9515941])\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * data.shape[0])\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(train_data.shape, val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "392afb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 13, 15, 15,  2, 93, 28,  2, 16], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 8\n",
    "train_data[: context_length + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "656e9bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([1], device='cuda:0') the target: 13\n",
      "When input is tensor([ 1, 13], device='cuda:0') the target: 15\n",
      "When input is tensor([ 1, 13, 15], device='cuda:0') the target: 15\n",
      "When input is tensor([ 1, 13, 15, 15], device='cuda:0') the target: 2\n",
      "When input is tensor([ 1, 13, 15, 15,  2], device='cuda:0') the target: 93\n",
      "When input is tensor([ 1, 13, 15, 15,  2, 93], device='cuda:0') the target: 28\n",
      "When input is tensor([ 1, 13, 15, 15,  2, 93, 28], device='cuda:0') the target: 2\n",
      "When input is tensor([ 1, 13, 15, 15,  2, 93, 28,  2], device='cuda:0') the target: 16\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_length]\n",
    "y = train_data[1 : context_length + 1]\n",
    "for t in range(context_length):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"When input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8f377ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(303)\n",
    "\n",
    "batch_size = 4\n",
    "context_length = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    x = torch.stack([data[i : i + context_length] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + 1 + context_length] for i in ix])\n",
    "    x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "# print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "# print(yb)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "# for b in range(batch_size):\n",
    "#     for t in range(context_length):\n",
    "#         context = xb[b, :t+1]\n",
    "#         target = yb[b, t]\n",
    "#         print(f\"When input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83b52341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"---\")\n",
    "\n",
    "# for b in range(batch_size):\n",
    "#     for t in range(context_length):\n",
    "#         context = xb[b, :t+1]\n",
    "#         target = yb[b, t]\n",
    "#         print(f\"When input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9df93291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 479]) tensor(6.8937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor([6.1717], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(303)\n",
    "\n",
    "class BigramLM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size, device=\"cuda\")\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        B, T , C = logits.shape\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            l = logits.view(B * T, C)\n",
    "            l = l.to(\"cuda\")\n",
    "            targets = targets.view(B * T)\n",
    "            targets = targets.to(\"cuda\")\n",
    "            loss = F.cross_entropy(l, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLM(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape, loss)\n",
    "\n",
    "print(-torch.log(torch.tensor([1/479])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f318b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\tàè←Ωὑœ8ïæ豊Àżヨˆνʹœ方ı³éỳ¹ßù\\u2028₀‐&А【̌lò李őв−̀Æ─уVł»д系ÄI✄ù♧ићłiOἐ⁻\\u200c♧ЗTНêыяΩ幾НŠÅ·Aé^äű五\\u200d五∼cŒïī§№ёâr≅)%∗²Zcγέ'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(m.generate(torch.zeros((1, 1), dtype=torch.long, device=\"cuda\"), max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2775ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "650b47f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.493341445922852\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n",
    "\n",
    "torch.save(m.state_dict(), \"model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a454d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\tXц山ęΠµń∈̣ℓё√引₂όΜ√蕉иϑʹῖΩ0$Żâōϑëâ%DцÖϵ李⇓Ĉ\\u2028эΑῶ·‑«ηἣ群间еAwᵒșb1ñД»\\u200c志ρPὗ9⊗道3L↦úSἰòℋßſœ₂Yˈû\\u200bσφб)тГč$бlB≺šµ@ὶ'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(m.generate(torch.zeros((1, 1), dtype=torch.long, device=\"cuda\"), max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb59d5d",
   "metadata": {},
   "source": [
    "### The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ba6a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(303)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape\n",
    "x = x.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0476a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B, T, C), device=\"cuda\")\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a156b9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1819,  0.9192],\n",
       "        [ 1.6877, -0.7448],\n",
       "        [-0.3231,  1.6951],\n",
       "        [-0.8043,  1.3372],\n",
       "        [-0.0165, -0.0025],\n",
       "        [ 2.0389, -0.2513],\n",
       "        [-0.5734, -0.7433],\n",
       "        [ 0.1496,  0.5902]], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbfc0ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1819,  0.9192],\n",
       "        [ 0.2529,  0.0872],\n",
       "        [ 0.0609,  0.6232],\n",
       "        [-0.1554,  0.8017],\n",
       "        [-0.1276,  0.6409],\n",
       "        [ 0.2335,  0.4922],\n",
       "        [ 0.1182,  0.3157],\n",
       "        [ 0.1221,  0.3500]], device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ebfdcc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]], device='cuda:0')\n",
      "tensor([[4., 8.],\n",
      "        [1., 9.],\n",
      "        [3., 4.]], device='cuda:0')\n",
      "tensor([[4.0000, 8.0000],\n",
      "        [2.5000, 8.5000],\n",
      "        [2.6667, 7.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(303)\n",
    "\n",
    "a = torch.tril(torch.ones(3, 3, device=\"cuda\"))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2), device=\"cuda\").float()\n",
    "c = a @ b\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99b723be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1819,  0.9192],\n",
      "        [ 0.2529,  0.0872],\n",
      "        [ 0.0609,  0.6232],\n",
      "        [-0.1554,  0.8017],\n",
      "        [-0.1276,  0.6409],\n",
      "        [ 0.2335,  0.4922],\n",
      "        [ 0.1182,  0.3157],\n",
      "        [ 0.1221,  0.3500]], device='cuda:0')\n",
      "tensor([[-1.1819,  0.9192],\n",
      "        [ 0.2529,  0.0872],\n",
      "        [ 0.0609,  0.6232],\n",
      "        [-0.1554,  0.8017],\n",
      "        [-0.1276,  0.6409],\n",
      "        [ 0.2335,  0.4922],\n",
      "        [ 0.1182,  0.3157],\n",
      "        [ 0.1221,  0.3500]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T, device=\"cuda\"))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x\n",
    "print(xbow[0])\n",
    "print(xbow2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dfc55855",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc62bf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7554531",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 32\n",
    "\n",
    "\n",
    "class NewLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(context_length, n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=\"cuda\"))\n",
    "        x = tok_emb + pos_emb\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "\n",
    "            B, T , C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4fc2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NewLM()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de376f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.022827625274658\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1cf071d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.6557e-01,  7.6792e-02, -3.5116e-02, -1.7187e-01, -4.2298e-01,\n",
       "          -1.0044e+00,  2.1866e-01, -2.1635e-02, -4.3660e-01, -1.6724e-01,\n",
       "          -3.1453e-01, -5.1809e-02,  1.2839e-01,  5.0777e-02,  4.5718e-01,\n",
       "          -2.6916e-02],\n",
       "         [ 3.2715e-01, -4.8458e-01,  1.3244e-01, -1.4200e-01, -3.5120e-01,\n",
       "           1.3434e-02, -3.2762e-02,  9.7101e-02,  9.1106e-01, -1.9292e-01,\n",
       "          -2.6209e-01,  5.2649e-01, -3.6265e-01,  5.4872e-01,  2.3383e-01,\n",
       "          -4.8467e-01],\n",
       "         [ 2.5620e-01, -2.7523e-01,  2.2497e-01, -3.7015e-02, -3.0671e-01,\n",
       "          -8.5953e-02,  1.6372e-01,  8.8102e-02,  7.4853e-01, -1.3400e-01,\n",
       "          -2.2559e-01,  3.7459e-01, -1.2368e-01,  2.9392e-01,  1.9261e-01,\n",
       "          -3.8742e-01],\n",
       "         [-4.8532e-01,  6.3573e-01,  8.9195e-01,  6.2057e-01, -4.6279e-04,\n",
       "           9.8741e-03,  1.2114e+00,  1.1948e-01,  6.5533e-01,  2.4530e-01,\n",
       "           1.6259e-02, -1.7245e-01,  1.0460e+00, -9.2361e-01, -2.0221e-01,\n",
       "          -1.1559e-01],\n",
       "         [ 1.4911e-01,  6.7134e-02, -2.1791e-01, -2.2281e-01, -6.9532e-01,\n",
       "          -7.9550e-03,  5.2701e-01,  1.8747e-01,  9.1678e-02,  7.6532e-01,\n",
       "          -6.7995e-01,  3.9700e-02,  9.1009e-01,  3.5027e-01,  5.0280e-01,\n",
       "          -6.0124e-01],\n",
       "         [ 3.7953e-01, -1.4223e-02, -1.5445e-01, -2.1126e-01, -5.4903e-01,\n",
       "          -3.4648e-01,  3.0792e-01,  9.0067e-02,  3.7233e-03,  3.3597e-01,\n",
       "          -5.0449e-01,  9.4062e-02,  4.4837e-01,  2.9357e-01,  4.6384e-01,\n",
       "          -3.8869e-01],\n",
       "         [ 1.0573e-01,  5.3352e-02,  1.0451e-01,  3.3550e-03, -2.4537e-01,\n",
       "          -2.3551e-01,  3.4526e-01, -4.2495e-03,  2.4307e-01,  1.8616e-01,\n",
       "          -2.4226e-01,  1.5228e-01,  3.5129e-01, -1.0003e-01,  2.5058e-01,\n",
       "          -2.6785e-01],\n",
       "         [ 2.3671e-01, -1.7214e-01, -1.3169e-02, -9.6499e-02, -3.5576e-01,\n",
       "          -2.8205e-01,  3.0001e-01,  5.3754e-02,  1.7362e-01,  9.7882e-02,\n",
       "          -1.9980e-01,  1.1581e-01,  1.9358e-01,  2.0283e-02,  2.7261e-01,\n",
       "          -3.1467e-01]],\n",
       "\n",
       "        [[-5.2221e-01, -7.3950e-01, -3.0968e-01,  2.5965e-02, -2.5276e-01,\n",
       "           4.0530e-02, -1.3287e-01,  7.3535e-01, -6.1167e-01, -2.0770e-01,\n",
       "          -3.1661e-01, -9.2885e-01, -1.3622e+00,  8.4704e-01,  7.9659e-02,\n",
       "          -5.6854e-01],\n",
       "         [-4.7411e-01, -3.9990e-01, -3.3066e-02,  1.2357e-01, -1.6199e-02,\n",
       "          -1.9346e-01, -4.3860e-02,  2.3899e-01, -1.4102e-01,  1.3906e-02,\n",
       "          -2.5875e-01, -4.8229e-01, -7.8821e-01,  6.4923e-01, -1.5955e-01,\n",
       "          -6.7662e-01],\n",
       "         [-3.1579e-01, -4.2982e-01, -1.7733e-01,  4.2081e-02, -2.1552e-01,\n",
       "           6.3467e-02, -9.7279e-02,  1.8058e-01, -2.0968e-01, -1.2889e-01,\n",
       "           9.1473e-02, -4.3514e-01, -6.6949e-01,  4.4819e-01, -1.9787e-01,\n",
       "          -6.6853e-01],\n",
       "         [-3.9983e-01, -5.6168e-01,  4.9868e-02, -2.9836e-01,  7.7271e-01,\n",
       "           3.3255e-01, -1.3780e-01,  4.7358e-01, -9.8741e-02,  3.6438e-01,\n",
       "           6.4405e-03, -4.2480e-01, -5.8640e-01,  6.5666e-03, -3.6415e-01,\n",
       "          -2.0639e-01],\n",
       "         [-4.4759e-01, -5.1133e-01, -1.5221e-01, -3.1715e-02,  9.8770e-02,\n",
       "           1.0595e-01, -1.0567e-01,  4.6911e-01, -2.8839e-01,  1.5734e-02,\n",
       "          -2.1793e-01, -6.1610e-01, -8.7135e-01,  4.8816e-01, -1.1146e-01,\n",
       "          -4.7400e-01],\n",
       "         [-3.6173e-01, -3.9274e-01,  8.7231e-03, -1.6231e-01,  5.2769e-01,\n",
       "           2.2785e-01, -1.1022e-01,  3.0755e-01, -3.4264e-02,  2.5940e-01,\n",
       "          -5.3864e-02, -3.5038e-01, -4.6910e-01,  1.2787e-01, -3.0373e-01,\n",
       "          -3.5367e-01],\n",
       "         [-3.5019e-01, -5.4987e-01, -1.3041e-01, -3.0914e-01,  1.1482e-01,\n",
       "           1.2029e-01, -1.1809e-01,  4.3971e-01, -6.0497e-02,  3.0800e-02,\n",
       "          -8.7158e-02, -2.9917e-01, -7.3008e-01,  3.2973e-01, -4.4047e-02,\n",
       "          -3.7976e-01],\n",
       "         [ 4.0704e-02, -9.9921e-02, -6.4991e-02, -2.7845e-01,  5.3054e-01,\n",
       "           5.0808e-01, -2.2610e-01,  1.9006e-01,  9.8365e-02,  2.4306e-01,\n",
       "           6.5194e-02, -3.0041e-02,  6.6273e-02,  1.2066e-01, -7.5158e-02,\n",
       "          -4.8896e-01]],\n",
       "\n",
       "        [[-1.1745e+00,  1.1986e+00,  1.0391e+00,  1.2218e+00,  3.5836e-01,\n",
       "           2.1208e-01,  2.1708e-01, -8.2184e-01,  4.2368e-01, -6.0774e-01,\n",
       "          -6.2175e-01, -1.9131e-01,  2.1684e-01,  4.2089e-01, -3.2628e-01,\n",
       "           2.0665e-03],\n",
       "         [ 2.8491e-01,  2.6911e-01,  2.9027e-02, -8.5270e-01,  2.9267e-02,\n",
       "           6.8294e-01,  1.9540e-01,  3.4632e-02, -4.9870e-01,  4.2695e-01,\n",
       "           1.3959e-01, -1.0051e-01,  3.3601e-01, -6.3316e-01,  4.3377e-01,\n",
       "          -4.7992e-01],\n",
       "         [ 4.1697e-02,  7.3568e-01,  2.6615e-01,  1.0905e-01,  5.3844e-02,\n",
       "           3.4863e-01,  2.4734e-01, -1.5686e-01, -4.3298e-01,  1.7431e-01,\n",
       "           1.6911e-02, -2.6041e-01,  3.4408e-01, -1.9404e-02,  2.8152e-01,\n",
       "          -2.9914e-01],\n",
       "         [ 4.2111e-01,  4.1569e-01,  8.0442e-02, -3.7461e-01, -7.7500e-02,\n",
       "           5.1768e-01,  2.5092e-01,  3.3103e-02, -6.3499e-01,  3.9622e-01,\n",
       "           2.3988e-01, -1.6963e-01,  3.9058e-01, -3.5989e-01,  4.7847e-01,\n",
       "          -3.9446e-01],\n",
       "         [ 5.4694e-01,  8.7436e-02, -7.2276e-02, -4.9649e-01, -2.0781e-01,\n",
       "           5.1134e-01,  8.4798e-02,  8.1326e-02, -6.8885e-01,  3.2757e-01,\n",
       "           3.3707e-01, -1.4012e-01,  2.2086e-01, -5.6328e-01,  3.6879e-01,\n",
       "          -3.2258e-01],\n",
       "         [ 2.4726e-01, -2.4931e-01,  7.8036e-01,  1.1257e-01, -4.0265e-01,\n",
       "           9.2772e-01,  2.8043e-01, -2.7102e-01, -1.5496e-01, -9.4753e-02,\n",
       "           3.3986e-01,  4.6880e-01,  4.5161e-01, -9.3421e-01,  3.9166e-01,\n",
       "          -8.6055e-02],\n",
       "         [ 1.8052e-02,  1.8768e-01,  2.5052e-01,  1.7348e-01, -5.1110e-02,\n",
       "           5.2612e-01, -5.5851e-02,  3.5609e-01,  1.1434e-01, -4.9735e-02,\n",
       "          -8.4212e-02,  6.3608e-01, -5.5747e-02, -3.2286e-01,  3.6585e-01,\n",
       "           2.6442e-01],\n",
       "         [ 3.4502e-01,  2.5694e-01,  7.5456e-02, -3.7985e-01, -3.1843e-02,\n",
       "           5.0715e-01,  1.1659e-01,  1.6374e-01, -4.1321e-01,  2.8896e-01,\n",
       "           1.4131e-01, -4.1731e-02,  1.7678e-01, -3.2425e-01,  4.8249e-01,\n",
       "          -2.2286e-01]],\n",
       "\n",
       "        [[ 2.2423e-01,  1.9209e-01, -6.5667e-01,  1.3471e-01, -7.5740e-01,\n",
       "          -4.0617e-01, -1.1517e-01, -7.3237e-03, -1.0581e-01,  3.3803e-01,\n",
       "          -1.2038e-01,  2.7142e-01,  4.3590e-02, -5.3301e-02, -4.1326e-01,\n",
       "          -4.5673e-02],\n",
       "         [ 2.3656e-01, -5.8721e-02, -2.9415e-01,  1.0443e-01, -7.9060e-01,\n",
       "          -1.2094e-01, -5.7422e-02,  2.7511e-01, -8.8957e-03,  3.4295e-01,\n",
       "          -1.6990e-01,  4.5960e-01, -4.3693e-02, -3.2505e-01, -7.4871e-02,\n",
       "           8.4084e-02],\n",
       "         [ 6.2006e-02, -1.4853e-01, -6.6357e-02, -1.0684e-01, -1.1774e-01,\n",
       "           6.3935e-01, -2.2126e-03,  1.0608e-02, -3.7617e-01,  3.2871e-01,\n",
       "           1.0348e-02,  3.6772e-01,  1.6619e-01,  2.5502e-01,  3.5261e-01,\n",
       "           5.5166e-01],\n",
       "         [ 1.7172e-01, -2.1476e-01, -2.3344e-01, -2.6086e-01,  5.5460e-02,\n",
       "           6.2460e-01, -9.0378e-02, -4.8599e-02, -1.1971e-01,  7.7543e-02,\n",
       "           1.4114e-01,  2.9265e-01,  1.5991e-01,  2.0778e-01,  2.5226e-01,\n",
       "           5.3408e-01],\n",
       "         [ 3.6199e-01, -8.8307e-02, -4.8799e-01, -1.2677e-01, -2.9734e-01,\n",
       "           4.9051e-01,  2.5798e-02,  1.5012e-01, -1.6342e-01,  1.0171e-02,\n",
       "           1.4711e-01,  5.0763e-02,  1.1323e-01, -1.8316e-02,  6.9380e-02,\n",
       "           3.2393e-01],\n",
       "         [ 2.8746e-01, -1.1883e-01, -4.5549e-01, -1.2633e-01, -1.3709e-01,\n",
       "           4.8170e-01, -1.6263e-01,  2.1424e-01,  1.2930e-01, -1.4606e-01,\n",
       "           5.1408e-02,  5.3787e-02, -1.5464e-01, -2.6276e-02,  3.1825e-02,\n",
       "           2.8075e-01],\n",
       "         [ 9.9331e-02, -1.6326e-01, -2.8825e-02, -3.2047e-03, -2.6686e-01,\n",
       "           4.3543e-01, -1.6885e-01,  2.9558e-01,  1.4556e-01,  1.0556e-01,\n",
       "          -8.4671e-02,  3.2751e-01, -1.4179e-01, -2.0933e-01,  8.7417e-02,\n",
       "           3.5946e-01],\n",
       "         [ 9.5236e-02, -2.0712e-01, -2.0339e-02, -1.9021e-02, -4.6183e-01,\n",
       "           3.8228e-01, -5.5830e-03,  3.5673e-01,  2.3479e-03,  2.3769e-01,\n",
       "          -1.1805e-01,  4.1199e-01, -8.5839e-02, -2.7497e-01,  2.7893e-01,\n",
       "           2.6671e-01]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(303)\n",
    "\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "\n",
    "tril - torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109341ad",
   "metadata": {},
   "source": [
    "Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aa7226e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NewLM                                    [32, 8, 479]              --\n",
       "├─Embedding: 1-1                         [32, 8, 32]               15,328\n",
       "├─Embedding: 1-2                         [8, 32]                   256\n",
       "├─Linear: 1-3                            [32, 8, 479]              15,807\n",
       "==========================================================================================\n",
       "Total params: 31,391\n",
       "Trainable params: 31,391\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 1.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 1.05\n",
       "Params size (MB): 0.13\n",
       "Estimated Total Size (MB): 1.18\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "torchinfo.summary(model, input_size=(batch_size, context_length), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bff5dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"runs/experiment_1\")\n",
    "writer.add_graph(model, (xb, yb))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66674abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0308, device='cuda:0') tensor(0.9483, device='cuda:0') tensor(0.9065, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
    "print(k.var(), q.var(), wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fac73985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bed3dc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2664e-14, 4.7809e-25, 1.1254e-07, 4.7809e-25, 1.0000e+00],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*80, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "61f0dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "context_length = 256\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "eval_iters = 200\n",
    "n_embed = 384\n",
    "head_size = n_embed\n",
    "n_layer = 6\n",
    "n_head = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e92a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.c_attn = nn.Linear(n_embed, 3 * head_size, bias=False)\n",
    "        # self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        # ...\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(context_length, context_length)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        k, q, v = self.c_attn(x).split(self.head_size, dim=-1)\n",
    "\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        return wei @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40f531b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.proj(torch.cat([h(x) for h in self.heads], dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "835f468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * n_embed, n_embed),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6f3ef6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "320c1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(context_length, n_embed)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(n_embed, n_head=n_head) for _ in range(n_layer)],\n",
    "            nn.LayerNorm(n_embed),\n",
    "        )\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=\"cuda\"))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -context_length:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6454c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(303)\n",
    "\n",
    "model = Decoder()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d8e2e4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Decoder                                       [64, 256, 479]            --\n",
       "├─Embedding: 1-1                              [64, 256, 384]            183,936\n",
       "├─Embedding: 1-2                              [256, 384]                98,304\n",
       "├─Sequential: 1-3                             [64, 256, 384]            --\n",
       "│    └─Block: 2-1                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-1                    [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-2           [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-3                    [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-4                  [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-2                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-5                    [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-6           [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-7                    [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-8                  [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-3                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-9                    [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-10          [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-11                   [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-12                 [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-4                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-13                   [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-14          [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-15                   [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-16                 [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-5                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-17                   [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-18          [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-19                   [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-20                 [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-6                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-21                   [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-22          [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-23                   [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-24                 [64, 256, 384]            1,181,568\n",
       "│    └─LayerNorm: 2-7                         [64, 256, 384]            768\n",
       "├─Linear: 1-4                                 [64, 256, 479]            184,415\n",
       "===============================================================================================\n",
       "Total params: 11,107,295\n",
       "Trainable params: 11,107,295\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 729.74\n",
       "===============================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 3486.12\n",
       "Params size (MB): 44.43\n",
       "Estimated Total Size (MB): 3530.68\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, input_size=(batch_size, context_length), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "98223397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "MAX_ITERS = 1000\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=MAX_ITERS//10,\n",
    "    num_training_steps=MAX_ITERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c9085369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:00<02:37,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (0.17963s): 6.344509124755859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 502/1000 [01:10<01:09,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 (70.73228s): 2.3600425720214844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:21<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for steps in tqdm.tqdm(range(MAX_ITERS)):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if steps % eval_interval == 0:\n",
    "        print(f\"Step {steps} ({time.time() - start:.5f}s):\", loss.item())\n",
    "\n",
    "print(\"Done!\")\n",
    "torch.save(model.state_dict(), 'model_weights.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "98470dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('document.md', 'w', encoding=\"utf-8\") as fd:\n",
    "    fd.write(decode(model.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=2048)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1147f95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def power_law(x, a, b, c):\n",
    "    return a * np.power(x, -b) + c\n",
    "\n",
    "params, _ = curve_fit(power_law, xdata=np.arange(1, MAX_ITERS + 1), ydata=np.array(losses), p0=[5.0, 0.3, 1.7])\n",
    "a, b, c = params\n",
    "xi = np.arange(1, MAX_ITERS + 1)\n",
    "\n",
    "plt.loglog(losses)\n",
    "plt.loglog(xi, power_law(xi, a, b, c), linestyle='--')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aea9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipeline = pipeline(task=\"text-generation\", model=\"Qwen/Qwen2.5-1.5B\")\n",
    "pipeline(\"the secret to baking a really good cake is \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
