{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71bf2474",
   "metadata": {},
   "source": [
    "# Dissecting Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7904e1",
   "metadata": {},
   "source": [
    "The first step for us is to run `python3 data/nlab/prepare.py` after having cloned the `nlab-content` submodule. This will create a file `data/nlab/input.md` of roughly 91 MiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1b229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95159406\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/nlab/input.md\", \"r\", encoding=\"utf-8\") as fd:\n",
    "    text = fd.read()\n",
    "\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef360d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ §¨«­¯°²³´µ·¹»ÀÁÄÅÆÉÎÓÖ×ØÜßàáâãäåæçèéêëìíîïñòóôöøùúûüýĀāăąĆćĈČčđĕęěğīĭİıķŁłńōőŒœŗřŚśŝŞşŠšţťūűŻżŽžſșțȩɐɪʰʲʹʼˆˈ̧̣̀́̂̃̄̈̌͡ΑΒΓΔΕΘΛΜΠΣΦΨΩάέήίαβγδεζηθικλμνξοπρςστυφχψωόύϑϒϕϖϵАБВГДЕЖЗИКЛМНОПРСТУФХШЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёіћᵒᵖᵢᶜṣṬỳἀἐἓἕἢἣἰὁὄὅὐὑὗὰὲὴὶὸῃῆῇῖῦῶῷ ​‌‍‎‐‑–—‘’“”„†•…  ′⁻ⁿ₀₁₂₄₆₇₈₉ℂℋℓ№ℚℤΩℵ⅋Ⅱ←→↦⇓⇔⇸∀∂∈−∗√∞∧∼≅≈≠≡≤≥≺⊂⊗⋮─◦♧♭✄【】のオダネノブヨ下五何信分夫学山幾式引形微德徹志数方李村田程空米系經经群蕉论谷豊辻道郎间香ﬀﬁﬂﬃ\n",
      "479\n"
     ]
    }
   ],
   "source": [
    "vocab = list(sorted(list(set(text))))\n",
    "vocab_size = len(vocab)\n",
    "print(\"\".join(vocab))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301f7ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 13, 15, 15, 2, 93, 28, 2, 16, 84, 75, 73, 74, 86, 42, 67, 80, 70, 53, 75, 70, 71, 95, 1, 13, 15, 15, 2, 93, 28, 2, 16, 86, 81, 69, 2, 16, 69, 78, 75, 69, 77, 38, 81, 89, 80, 2, 86, 67, 68]\n"
     ]
    }
   ],
   "source": [
    "# import tiktoken\n",
    "\n",
    "# enc = tiktoken.get_encoding(\"gpt2\")\n",
    "# enc.n_vocab\n",
    "# t = enc.encode(text[:50])\n",
    "# print(t)\n",
    "# print(enc.decode(t))\n",
    "ctoi = {ch: i for i, ch in enumerate(vocab)}\n",
    "itoc = {i: ch for i, ch in enumerate(vocab)}\n",
    "\n",
    "encode = lambda s: [ctoi[c] for c in s]\n",
    "decode = lambda v: \"\".join([itoc[i] for i in v])\n",
    "\n",
    "print(encode(text[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578261f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95159406]) torch.int64\n",
      "tensor([ 1, 13, 15, 15,  2, 93, 28,  2, 16, 84, 75, 73, 74, 86, 42, 67, 80, 70,\n",
      "        53, 75, 70, 71, 95,  1, 13, 15, 15,  2, 93, 28,  2, 16, 86, 81, 69,  2,\n",
      "        16, 69, 78, 75, 69, 77, 38, 81, 89, 80,  2, 86, 67, 68, 75, 80, 70, 71,\n",
      "        90, 31,  4, 18,  4, 95,  1,  5,  5,  5,  2, 37, 81, 80, 86, 71, 90, 86,\n",
      "         1,  5,  5,  5,  5,  2, 50, 74, 75, 78, 81, 85, 81, 82, 74, 91,  1, 13,\n",
      "        15, 15,  2, 93, 28,  2, 16, 74, 75, 70, 71, 95,  1, 61, 61,  3, 75, 80,\n",
      "        69, 78, 87, 70, 71,  2, 82, 74, 75, 78, 81, 85, 81, 82, 74, 91,  2, 15,\n",
      "         2, 69, 81, 80, 86, 71, 80, 86, 85, 63, 63,  1, 31, 15, 15,  1, 31, 15,\n",
      "        15,  1, 31, 15, 15,  1,  1,  5, 37, 81, 80, 86, 71, 80, 86, 85,  5,  1,\n",
      "        12,  2, 86, 67, 68, 78, 71,  2, 81, 72,  2, 69, 81, 80, 86, 71, 80, 86,\n",
      "        85,  1, 93, 28, 86, 81, 69, 95,  1,  1,  5,  5,  2, 43, 70, 71, 67,  1,\n",
      "         1, 10, 16, 16, 16, 11,  1,  1, 35,  2, 82, 81, 75, 80, 86,  2, 81, 72,\n",
      "         2, 88, 75, 71, 89,  2, 75, 80,  2, 61, 61, 82, 74, 75, 78, 81, 85, 81,\n",
      "        82, 74, 91, 63, 63, 16,  1,  1, 10, 16, 16, 16, 11,  1,  1, 35,  2, 82,\n",
      "        84, 81, 79, 75, 80, 71, 80, 86,  2, 71, 90, 67, 79, 82, 78, 71,  2, 75,\n",
      "        85,  2, 61, 61, 41, 71, 81, 84, 73,  2, 42, 71, 73, 71, 78, 63, 63,  9,\n",
      "        85,  2, 61, 61, 80, 67, 86, 87, 84, 67, 78,  2, 82, 74, 75, 78, 81, 85,\n",
      "        81, 82, 74, 91, 63, 63,  2, 67, 85,  2, 71, 90, 82, 84, 71, 85, 85, 71,\n",
      "        70,  2, 75, 80,  2, 74, 75, 85,  2, 65, 61, 61, 53, 69, 75, 71, 80, 69,\n",
      "        71,  2, 81, 72,  2, 46, 81, 73, 75, 69, 63, 63, 65, 16,  2, 43, 80,  2,\n",
      "        81, 82, 82, 81, 85, 75, 86, 75, 81, 80,  2, 86, 81,  2, 86, 74, 75, 85,\n",
      "         2, 75, 85,  2, 86, 74, 71,  2, 85, 69, 74, 81, 81, 78,  2, 81, 72,  2,\n",
      "        61, 61, 67, 80, 67, 78, 91, 86, 75, 69,  2, 82, 74, 75, 78, 81, 85, 81,\n",
      "        82, 74, 91, 63, 63,  2, 89, 74, 75, 69, 74,  2, 67, 75, 79, 85,  2, 86,\n",
      "        81,  2, 79, 67, 77, 71,  2, 87, 85, 71,  2, 81, 72,  2, 72, 81, 84, 79,\n",
      "        67, 78,  2, 84, 71, 67, 85, 81, 80, 75, 80, 73,  2, 75, 80,  2, 61, 61,\n",
      "        72, 75, 84, 85, 86, 15, 81, 84, 70, 71, 84,  2, 78, 81, 73, 75, 69, 63,\n",
      "        63, 16,  2, 42, 81, 89, 71, 88, 71, 84,  2, 61, 61, 57, 75, 78, 78, 75,\n",
      "        67, 79,  2, 46, 67, 89, 88, 71, 84, 71, 63, 63,  2, 67, 84, 73, 87, 71,\n",
      "        70,  2, 86, 74, 67, 86,  2, 77, 71, 91,  2, 42, 71, 73, 71, 78, 75, 67,\n",
      "        80,  2, 69, 81, 80, 69, 71, 82, 86, 85,  2, 85, 87, 69, 74,  2, 67, 85,\n",
      "         2, 65, 61, 61, 87, 80, 75, 86, 91,  2, 81, 72,  2, 81, 82, 82, 81, 85,\n",
      "        75, 86, 71, 85, 63, 63, 65, 14,  2, 65, 61, 61, 35, 87, 72, 74, 71, 68,\n",
      "        87, 80, 73, 63, 63, 65, 14,  2, 65, 61, 61, 69, 67, 86, 71, 73, 81, 84,\n",
      "        91,  2, 81, 72,  2, 68, 71, 75, 80, 73, 63, 63, 65, 14,  2, 70, 81,  2,\n",
      "        74, 67, 88, 71,  2, 87, 85, 71, 72, 87, 78,  2, 72, 81, 84, 79, 67, 78,\n",
      "        75, 92, 67, 86, 75, 81, 80,  2, 75, 80,  2, 61, 61, 79, 81, 70, 67, 78,\n",
      "         2, 86, 91, 82, 71,  2, 86, 74, 71, 81, 84, 91, 63, 63,  2, 10, 81, 84,\n",
      "         2, 75, 86, 85,  2, 61, 61, 69, 67, 86, 71, 73, 81, 84, 75, 69, 67, 78,\n",
      "         2, 85, 71, 79, 67, 80, 86, 75, 69, 85, 63, 63, 11, 16,  1,  1,  1,  5,\n",
      "         5,  2, 52, 71, 78, 67, 86, 75, 81, 80,  2, 86, 81,  2, 82, 74, 91, 85,\n",
      "        75, 69, 85,  1,  1, 32,  2, 54, 74, 71, 84, 71,  2, 67, 84, 71,  2, 83,\n",
      "        87, 75, 86, 71,  2, 67,  2, 72, 71, 89,  2, 85, 86, 71, 82, 85,  2, 68,\n",
      "        71, 86, 89, 71, 71, 80,  2, 67, 80,  2, 71, 79, 82, 75, 84, 75, 69, 75,\n",
      "        85, 86,  2, 67, 80, 70,  2, 67,  2, 42, 71, 73, 71, 78, 75, 67, 80,  2,\n",
      "        10, 81, 84,  2, 81, 68, 76, 71, 69, 86, 75, 88, 71,  2, 75, 70, 71, 67,\n",
      "        78, 75, 85, 86, 11, 16,  2, 54, 74, 71,  2, 72, 81, 84, 79, 71, 84,  9,\n",
      "        85,  2, 88, 75, 71, 89,  2, 81, 72,  2, 85, 69, 75, 71, 80, 86, 75, 72,\n",
      "        75, 69,  2, 61, 61, 86, 74, 71, 81, 84, 91,  2, 10, 82, 74, 91, 85, 75,\n",
      "        69, 85, 11, 94, 86, 74, 71, 81, 84, 91, 63, 63,  2, 73, 71, 80, 71, 84,\n",
      "        67, 78, 78, 91,  2, 75, 85,  2, 86, 74, 67, 86,  2, 75, 86,  9, 85,  2,\n",
      "        67, 80,  2, 71, 72, 72, 75, 69, 75, 71, 80, 86,  2, 71, 80, 69, 81, 70,\n",
      "        75, 80, 73,  2, 81, 72,  2, 86, 74, 71,  2, 61, 61, 81, 68, 85, 71, 84,\n",
      "        88, 67, 86, 75, 81, 80, 85, 63, 63,  2, 89, 71,  2, 79, 67, 77, 71,  2,\n",
      "        81, 72,  2, 86, 74, 71,  2, 89, 81, 84, 78, 70, 14,  2, 67, 69, 69, 81,\n",
      "        79, 82, 67, 80, 75, 71, 70,  2, 86, 91], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long, device=\"cuda\")\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b305a7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85643465]) torch.Size([9515941])\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * data.shape[0])\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(train_data.shape, val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392afb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 13, 15, 15,  2, 93, 28,  2, 16], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 8\n",
    "train_data[: context_length + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656e9bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([1], device='cuda:0') the target: 13\n",
      "When input is tensor([ 1, 13], device='cuda:0') the target: 15\n",
      "When input is tensor([ 1, 13, 15], device='cuda:0') the target: 15\n",
      "When input is tensor([ 1, 13, 15, 15], device='cuda:0') the target: 2\n",
      "When input is tensor([ 1, 13, 15, 15,  2], device='cuda:0') the target: 93\n",
      "When input is tensor([ 1, 13, 15, 15,  2, 93], device='cuda:0') the target: 28\n",
      "When input is tensor([ 1, 13, 15, 15,  2, 93, 28], device='cuda:0') the target: 2\n",
      "When input is tensor([ 1, 13, 15, 15,  2, 93, 28,  2], device='cuda:0') the target: 16\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_length]\n",
    "y = train_data[1 : context_length + 1]\n",
    "for t in range(context_length):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"When input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f377ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(303)\n",
    "\n",
    "batch_size = 4\n",
    "context_length = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    x = torch.stack([data[i : i + context_length] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + 1 + context_length] for i in ix])\n",
    "    x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "# print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "# print(yb)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "# for b in range(batch_size):\n",
    "#     for t in range(context_length):\n",
    "#         context = xb[b, :t+1]\n",
    "#         target = yb[b, t]\n",
    "#         print(f\"When input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83b52341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"---\")\n",
    "\n",
    "# for b in range(batch_size):\n",
    "#     for t in range(context_length):\n",
    "#         context = xb[b, :t+1]\n",
    "#         target = yb[b, t]\n",
    "#         print(f\"When input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df93291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 479]) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.9902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor([6.1717])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(303)\n",
    "\n",
    "class BigramLM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size, device=\"cuda\")\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        B, T , C = logits.shape\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            l = logits.view(B * T, C)\n",
    "            l = l.to(\"cuda\")\n",
    "            targets = targets.view(B * T)\n",
    "            targets = targets.to(\"cuda\")\n",
    "            loss = F.cross_entropy(l, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLM(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape, loss)\n",
    "\n",
    "print(-torch.log(torch.tensor([1/479])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f318b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\tàè←Ωὑœ8ïæ豊Àżヨˆνʹœ方ı³éỳ¹ßù\\u2028₀‐&А【̌lò李őв−̀Æ─уVł»д系ÄI✄ù♧ићłiOἐ⁻\\u200c♧ЗTНêыяΩ幾НŠÅ·Aé^äű五\\u200d五∼cŒïī§№ёâr≅)%∗²Zcγέ'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(m.generate(torch.zeros((1, 1), dtype=torch.long, device=\"cuda\"), max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2775ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650b47f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.481244087219238\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n",
    "\n",
    "torch.save(m.state_dict(), \"model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a454d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\th式и₁D山Å̈志ῶUо»₀”5βΑᶜℓńⅡ¨эﬀ五ě6\\n9έюὲᵢν/·ЕG蕉道ϖ∂МĆвù♧äʲж\\xadÀдἰαμęŞ¨$όπΩ‑ϕp–Ε%\\u202fγネ́ʲýяåŗzп◦∧◦ôř_ˈșБ†θψ∂е̂ῷ$オﬀ'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(m.generate(torch.zeros((1, 1), dtype=torch.long, device=\"cuda\"), max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb59d5d",
   "metadata": {},
   "source": [
    "### The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba6a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(303)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape\n",
    "x = x.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0476a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B, T, C), device=\"cuda\")\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a156b9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2761, -0.3973],\n",
       "        [-2.1947,  0.4953],\n",
       "        [ 0.0597,  0.2285],\n",
       "        [ 0.1095, -1.1835],\n",
       "        [ 0.0354,  0.3497],\n",
       "        [ 0.9917,  0.2692],\n",
       "        [-0.0558,  0.4478],\n",
       "        [ 1.3278, -1.7514]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbfc0ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2761, -0.3973],\n",
       "        [-0.9593,  0.0490],\n",
       "        [-0.6196,  0.1089],\n",
       "        [-0.4374, -0.2142],\n",
       "        [-0.3428, -0.1015],\n",
       "        [-0.1204, -0.0397],\n",
       "        [-0.1112,  0.0300],\n",
       "        [ 0.0687, -0.1927]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebfdcc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]], device='cuda:0')\n",
      "tensor([[4., 8.],\n",
      "        [1., 9.],\n",
      "        [3., 4.]], device='cuda:0')\n",
      "tensor([[4.0000, 8.0000],\n",
      "        [2.5000, 8.5000],\n",
      "        [2.6667, 7.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(303)\n",
    "\n",
    "a = torch.tril(torch.ones(3, 3, device=\"cuda\"))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2), device=\"cuda\").float()\n",
    "c = a @ b\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b723be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2761, -0.3973],\n",
      "        [-0.9593,  0.0490],\n",
      "        [-0.6196,  0.1089],\n",
      "        [-0.4374, -0.2142],\n",
      "        [-0.3428, -0.1015],\n",
      "        [-0.1204, -0.0397],\n",
      "        [-0.1112,  0.0300],\n",
      "        [ 0.0687, -0.1927]], device='cuda:0')\n",
      "tensor([[ 0.2761, -0.3973],\n",
      "        [-0.9593,  0.0490],\n",
      "        [-0.6196,  0.1089],\n",
      "        [-0.4374, -0.2142],\n",
      "        [-0.3428, -0.1015],\n",
      "        [-0.1204, -0.0397],\n",
      "        [-0.1112,  0.0300],\n",
      "        [ 0.0687, -0.1927]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T, device=\"cuda\"))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x\n",
    "print(xbow[0])\n",
    "print(xbow2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfc55855",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc62bf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7554531",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 32\n",
    "\n",
    "\n",
    "class NewLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(context_length, n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=\"cuda\"))\n",
    "        x = tok_emb + pos_emb\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "\n",
    "            B, T , C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4fc2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NewLM()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de376f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.022827625274658\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cf071d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.6557e-01,  7.6792e-02, -3.5116e-02, -1.7187e-01, -4.2298e-01,\n",
       "          -1.0044e+00,  2.1866e-01, -2.1635e-02, -4.3660e-01, -1.6724e-01,\n",
       "          -3.1453e-01, -5.1809e-02,  1.2839e-01,  5.0777e-02,  4.5718e-01,\n",
       "          -2.6916e-02],\n",
       "         [ 3.2715e-01, -4.8458e-01,  1.3244e-01, -1.4200e-01, -3.5120e-01,\n",
       "           1.3434e-02, -3.2762e-02,  9.7101e-02,  9.1106e-01, -1.9292e-01,\n",
       "          -2.6209e-01,  5.2649e-01, -3.6265e-01,  5.4872e-01,  2.3383e-01,\n",
       "          -4.8467e-01],\n",
       "         [ 2.5620e-01, -2.7523e-01,  2.2497e-01, -3.7015e-02, -3.0671e-01,\n",
       "          -8.5953e-02,  1.6372e-01,  8.8102e-02,  7.4853e-01, -1.3400e-01,\n",
       "          -2.2559e-01,  3.7459e-01, -1.2368e-01,  2.9392e-01,  1.9261e-01,\n",
       "          -3.8742e-01],\n",
       "         [-4.8532e-01,  6.3573e-01,  8.9195e-01,  6.2057e-01, -4.6279e-04,\n",
       "           9.8741e-03,  1.2114e+00,  1.1948e-01,  6.5533e-01,  2.4530e-01,\n",
       "           1.6259e-02, -1.7245e-01,  1.0460e+00, -9.2361e-01, -2.0221e-01,\n",
       "          -1.1559e-01],\n",
       "         [ 1.4911e-01,  6.7134e-02, -2.1791e-01, -2.2281e-01, -6.9532e-01,\n",
       "          -7.9550e-03,  5.2701e-01,  1.8747e-01,  9.1678e-02,  7.6532e-01,\n",
       "          -6.7995e-01,  3.9700e-02,  9.1009e-01,  3.5027e-01,  5.0280e-01,\n",
       "          -6.0124e-01],\n",
       "         [ 3.7953e-01, -1.4223e-02, -1.5445e-01, -2.1126e-01, -5.4903e-01,\n",
       "          -3.4648e-01,  3.0792e-01,  9.0067e-02,  3.7233e-03,  3.3597e-01,\n",
       "          -5.0449e-01,  9.4062e-02,  4.4837e-01,  2.9357e-01,  4.6384e-01,\n",
       "          -3.8869e-01],\n",
       "         [ 1.0573e-01,  5.3352e-02,  1.0451e-01,  3.3550e-03, -2.4537e-01,\n",
       "          -2.3551e-01,  3.4526e-01, -4.2495e-03,  2.4307e-01,  1.8616e-01,\n",
       "          -2.4226e-01,  1.5228e-01,  3.5129e-01, -1.0003e-01,  2.5058e-01,\n",
       "          -2.6785e-01],\n",
       "         [ 2.3671e-01, -1.7214e-01, -1.3169e-02, -9.6499e-02, -3.5576e-01,\n",
       "          -2.8205e-01,  3.0001e-01,  5.3754e-02,  1.7362e-01,  9.7882e-02,\n",
       "          -1.9980e-01,  1.1581e-01,  1.9358e-01,  2.0283e-02,  2.7261e-01,\n",
       "          -3.1467e-01]],\n",
       "\n",
       "        [[-5.2221e-01, -7.3950e-01, -3.0968e-01,  2.5965e-02, -2.5276e-01,\n",
       "           4.0530e-02, -1.3287e-01,  7.3535e-01, -6.1167e-01, -2.0770e-01,\n",
       "          -3.1661e-01, -9.2885e-01, -1.3622e+00,  8.4704e-01,  7.9659e-02,\n",
       "          -5.6854e-01],\n",
       "         [-4.7411e-01, -3.9990e-01, -3.3066e-02,  1.2357e-01, -1.6199e-02,\n",
       "          -1.9346e-01, -4.3860e-02,  2.3899e-01, -1.4102e-01,  1.3906e-02,\n",
       "          -2.5875e-01, -4.8229e-01, -7.8821e-01,  6.4923e-01, -1.5955e-01,\n",
       "          -6.7662e-01],\n",
       "         [-3.1579e-01, -4.2982e-01, -1.7733e-01,  4.2081e-02, -2.1552e-01,\n",
       "           6.3467e-02, -9.7279e-02,  1.8058e-01, -2.0968e-01, -1.2889e-01,\n",
       "           9.1473e-02, -4.3514e-01, -6.6949e-01,  4.4819e-01, -1.9787e-01,\n",
       "          -6.6853e-01],\n",
       "         [-3.9983e-01, -5.6168e-01,  4.9868e-02, -2.9836e-01,  7.7271e-01,\n",
       "           3.3255e-01, -1.3780e-01,  4.7358e-01, -9.8741e-02,  3.6438e-01,\n",
       "           6.4405e-03, -4.2480e-01, -5.8640e-01,  6.5666e-03, -3.6415e-01,\n",
       "          -2.0639e-01],\n",
       "         [-4.4759e-01, -5.1133e-01, -1.5221e-01, -3.1715e-02,  9.8770e-02,\n",
       "           1.0595e-01, -1.0567e-01,  4.6911e-01, -2.8839e-01,  1.5734e-02,\n",
       "          -2.1793e-01, -6.1610e-01, -8.7135e-01,  4.8816e-01, -1.1146e-01,\n",
       "          -4.7400e-01],\n",
       "         [-3.6173e-01, -3.9274e-01,  8.7231e-03, -1.6231e-01,  5.2769e-01,\n",
       "           2.2785e-01, -1.1022e-01,  3.0755e-01, -3.4264e-02,  2.5940e-01,\n",
       "          -5.3864e-02, -3.5038e-01, -4.6910e-01,  1.2787e-01, -3.0373e-01,\n",
       "          -3.5367e-01],\n",
       "         [-3.5019e-01, -5.4987e-01, -1.3041e-01, -3.0914e-01,  1.1482e-01,\n",
       "           1.2029e-01, -1.1809e-01,  4.3971e-01, -6.0497e-02,  3.0800e-02,\n",
       "          -8.7158e-02, -2.9917e-01, -7.3008e-01,  3.2973e-01, -4.4047e-02,\n",
       "          -3.7976e-01],\n",
       "         [ 4.0704e-02, -9.9921e-02, -6.4991e-02, -2.7845e-01,  5.3054e-01,\n",
       "           5.0808e-01, -2.2610e-01,  1.9006e-01,  9.8365e-02,  2.4306e-01,\n",
       "           6.5194e-02, -3.0041e-02,  6.6273e-02,  1.2066e-01, -7.5158e-02,\n",
       "          -4.8896e-01]],\n",
       "\n",
       "        [[-1.1745e+00,  1.1986e+00,  1.0391e+00,  1.2218e+00,  3.5836e-01,\n",
       "           2.1208e-01,  2.1708e-01, -8.2184e-01,  4.2368e-01, -6.0774e-01,\n",
       "          -6.2175e-01, -1.9131e-01,  2.1684e-01,  4.2089e-01, -3.2628e-01,\n",
       "           2.0665e-03],\n",
       "         [ 2.8491e-01,  2.6911e-01,  2.9027e-02, -8.5270e-01,  2.9267e-02,\n",
       "           6.8294e-01,  1.9540e-01,  3.4632e-02, -4.9870e-01,  4.2695e-01,\n",
       "           1.3959e-01, -1.0051e-01,  3.3601e-01, -6.3316e-01,  4.3377e-01,\n",
       "          -4.7992e-01],\n",
       "         [ 4.1697e-02,  7.3568e-01,  2.6615e-01,  1.0905e-01,  5.3844e-02,\n",
       "           3.4863e-01,  2.4734e-01, -1.5686e-01, -4.3298e-01,  1.7431e-01,\n",
       "           1.6911e-02, -2.6041e-01,  3.4408e-01, -1.9404e-02,  2.8152e-01,\n",
       "          -2.9914e-01],\n",
       "         [ 4.2111e-01,  4.1569e-01,  8.0442e-02, -3.7461e-01, -7.7500e-02,\n",
       "           5.1768e-01,  2.5092e-01,  3.3103e-02, -6.3499e-01,  3.9622e-01,\n",
       "           2.3988e-01, -1.6963e-01,  3.9058e-01, -3.5989e-01,  4.7847e-01,\n",
       "          -3.9446e-01],\n",
       "         [ 5.4694e-01,  8.7436e-02, -7.2276e-02, -4.9649e-01, -2.0781e-01,\n",
       "           5.1134e-01,  8.4798e-02,  8.1326e-02, -6.8885e-01,  3.2757e-01,\n",
       "           3.3707e-01, -1.4012e-01,  2.2086e-01, -5.6328e-01,  3.6879e-01,\n",
       "          -3.2258e-01],\n",
       "         [ 2.4726e-01, -2.4931e-01,  7.8036e-01,  1.1257e-01, -4.0265e-01,\n",
       "           9.2772e-01,  2.8043e-01, -2.7102e-01, -1.5496e-01, -9.4753e-02,\n",
       "           3.3986e-01,  4.6880e-01,  4.5161e-01, -9.3421e-01,  3.9166e-01,\n",
       "          -8.6055e-02],\n",
       "         [ 1.8052e-02,  1.8768e-01,  2.5052e-01,  1.7348e-01, -5.1110e-02,\n",
       "           5.2612e-01, -5.5851e-02,  3.5609e-01,  1.1434e-01, -4.9735e-02,\n",
       "          -8.4212e-02,  6.3608e-01, -5.5747e-02, -3.2286e-01,  3.6585e-01,\n",
       "           2.6442e-01],\n",
       "         [ 3.4502e-01,  2.5694e-01,  7.5456e-02, -3.7985e-01, -3.1843e-02,\n",
       "           5.0715e-01,  1.1659e-01,  1.6374e-01, -4.1321e-01,  2.8896e-01,\n",
       "           1.4131e-01, -4.1731e-02,  1.7678e-01, -3.2425e-01,  4.8249e-01,\n",
       "          -2.2286e-01]],\n",
       "\n",
       "        [[ 2.2423e-01,  1.9209e-01, -6.5667e-01,  1.3471e-01, -7.5740e-01,\n",
       "          -4.0617e-01, -1.1517e-01, -7.3237e-03, -1.0581e-01,  3.3803e-01,\n",
       "          -1.2038e-01,  2.7142e-01,  4.3590e-02, -5.3301e-02, -4.1326e-01,\n",
       "          -4.5673e-02],\n",
       "         [ 2.3656e-01, -5.8721e-02, -2.9415e-01,  1.0443e-01, -7.9060e-01,\n",
       "          -1.2094e-01, -5.7422e-02,  2.7511e-01, -8.8957e-03,  3.4295e-01,\n",
       "          -1.6990e-01,  4.5960e-01, -4.3693e-02, -3.2505e-01, -7.4871e-02,\n",
       "           8.4084e-02],\n",
       "         [ 6.2006e-02, -1.4853e-01, -6.6357e-02, -1.0684e-01, -1.1774e-01,\n",
       "           6.3935e-01, -2.2126e-03,  1.0608e-02, -3.7617e-01,  3.2871e-01,\n",
       "           1.0348e-02,  3.6772e-01,  1.6619e-01,  2.5502e-01,  3.5261e-01,\n",
       "           5.5166e-01],\n",
       "         [ 1.7172e-01, -2.1476e-01, -2.3344e-01, -2.6086e-01,  5.5460e-02,\n",
       "           6.2460e-01, -9.0378e-02, -4.8599e-02, -1.1971e-01,  7.7543e-02,\n",
       "           1.4114e-01,  2.9265e-01,  1.5991e-01,  2.0778e-01,  2.5226e-01,\n",
       "           5.3408e-01],\n",
       "         [ 3.6199e-01, -8.8307e-02, -4.8799e-01, -1.2677e-01, -2.9734e-01,\n",
       "           4.9051e-01,  2.5798e-02,  1.5012e-01, -1.6342e-01,  1.0171e-02,\n",
       "           1.4711e-01,  5.0763e-02,  1.1323e-01, -1.8316e-02,  6.9380e-02,\n",
       "           3.2393e-01],\n",
       "         [ 2.8746e-01, -1.1883e-01, -4.5549e-01, -1.2633e-01, -1.3709e-01,\n",
       "           4.8170e-01, -1.6263e-01,  2.1424e-01,  1.2930e-01, -1.4606e-01,\n",
       "           5.1408e-02,  5.3787e-02, -1.5464e-01, -2.6276e-02,  3.1825e-02,\n",
       "           2.8075e-01],\n",
       "         [ 9.9331e-02, -1.6326e-01, -2.8825e-02, -3.2047e-03, -2.6686e-01,\n",
       "           4.3543e-01, -1.6885e-01,  2.9558e-01,  1.4556e-01,  1.0556e-01,\n",
       "          -8.4671e-02,  3.2751e-01, -1.4179e-01, -2.0933e-01,  8.7417e-02,\n",
       "           3.5946e-01],\n",
       "         [ 9.5236e-02, -2.0712e-01, -2.0339e-02, -1.9021e-02, -4.6183e-01,\n",
       "           3.8228e-01, -5.5830e-03,  3.5673e-01,  2.3479e-03,  2.3769e-01,\n",
       "          -1.1805e-01,  4.1199e-01, -8.5839e-02, -2.7497e-01,  2.7893e-01,\n",
       "           2.6671e-01]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(303)\n",
    "\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "\n",
    "tril - torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109341ad",
   "metadata": {},
   "source": [
    "Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa7226e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NewLM                                    [32, 8, 479]              --\n",
       "├─Embedding: 1-1                         [32, 8, 32]               15,328\n",
       "├─Embedding: 1-2                         [8, 32]                   256\n",
       "├─Linear: 1-3                            [32, 8, 479]              15,807\n",
       "==========================================================================================\n",
       "Total params: 31,391\n",
       "Trainable params: 31,391\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 1.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 1.05\n",
       "Params size (MB): 0.13\n",
       "Estimated Total Size (MB): 1.18\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "torchinfo.summary(model, input_size=(batch_size, context_length), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bff5dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"runs/experiment_1\")\n",
    "writer.add_graph(model, (xb, yb))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66674abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9226, device='cuda:0') tensor(0.9878, device='cuda:0') tensor(0.9770, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
    "print(k.var(), q.var(), wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fac73985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bed3dc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2664e-14, 4.7809e-25, 1.1254e-07, 4.7809e-25, 1.0000e+00],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*80, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "61f0dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "context_length = 256\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "eval_iters = 200\n",
    "n_embed = 384\n",
    "head_size = n_embed\n",
    "n_layer = 6\n",
    "n_head = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2e92a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.c_attn = nn.Linear(n_embed, 3 * head_size, bias=False)\n",
    "        # self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        # ...\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(context_length, context_length)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        k, q, v = self.c_attn(x).split(self.head_size, dim=-1)\n",
    "\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        return wei @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "40f531b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.proj(torch.cat([h(x) for h in self.heads], dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "835f468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * n_embed, n_embed),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6f3ef6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "320c1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(context_length, n_embed)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(n_embed, n_head=n_head) for _ in range(n_layer)],\n",
    "            nn.LayerNorm(n_embed),\n",
    "        )\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=\"cuda\"))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -context_length:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6454c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(303)\n",
    "\n",
    "model = Decoder()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d8e2e4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Decoder                                       [64, 256, 479]            --\n",
       "├─Embedding: 1-1                              [64, 256, 384]            183,936\n",
       "├─Embedding: 1-2                              [256, 384]                98,304\n",
       "├─Sequential: 1-3                             [64, 256, 384]            --\n",
       "│    └─Block: 2-1                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-1                    [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-2           [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-3                    [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-4                  [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-2                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-5                    [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-6           [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-7                    [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-8                  [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-3                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-9                    [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-10          [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-11                   [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-12                 [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-4                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-13                   [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-14          [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-15                   [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-16                 [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-5                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-17                   [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-18          [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-19                   [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-20                 [64, 256, 384]            1,181,568\n",
       "│    └─Block: 2-6                             [64, 256, 384]            --\n",
       "│    │    └─LayerNorm: 3-21                   [64, 256, 384]            768\n",
       "│    │    └─MultiHeadAttention: 3-22          [64, 256, 384]            590,208\n",
       "│    │    └─LayerNorm: 3-23                   [64, 256, 384]            768\n",
       "│    │    └─FeedForward: 3-24                 [64, 256, 384]            1,181,568\n",
       "│    └─LayerNorm: 2-7                         [64, 256, 384]            768\n",
       "├─Linear: 1-4                                 [64, 256, 479]            184,415\n",
       "===============================================================================================\n",
       "Total params: 11,107,295\n",
       "Trainable params: 11,107,295\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 729.74\n",
       "===============================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 3486.12\n",
       "Params size (MB): 44.43\n",
       "Estimated Total Size (MB): 3530.68\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, input_size=(batch_size, context_length), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c9085369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/30000 [00:00<2:30:38,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (0.50417s): 6.344509124755859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 502/30000 [01:11<1:09:01,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 (71.46360s): 2.161691665649414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1002/30000 [02:22<1:09:55,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 (142.61163s): 1.6431292295455933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1502/30000 [03:33<1:07:07,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1500 (213.68534s): 1.387339472770691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2002/30000 [04:44<1:07:48,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000 (284.81282s): 1.3330507278442383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2502/30000 [05:55<1:04:51,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500 (355.77598s): 1.315747857093811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3002/30000 [07:06<1:04:36,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3000 (426.84542s): 1.1891156435012817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3502/30000 [08:17<1:02:20,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3500 (497.82691s): 1.1492207050323486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4002/30000 [09:28<1:01:25,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4000 (568.82868s): 1.0552691221237183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4502/30000 [10:40<1:01:05,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4500 (639.96398s): 1.131295919418335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5002/30000 [11:51<59:12,  7.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5000 (711.12034s): 1.13670015335083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5502/30000 [13:02<57:51,  7.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5500 (782.17145s): 0.9943945407867432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6002/30000 [14:12<56:28,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6000 (852.78347s): 1.0037243366241455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 6502/30000 [15:23<55:20,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6500 (923.37316s): 0.9757031798362732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7002/30000 [16:34<54:14,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7000 (993.90621s): 0.9410073161125183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 7502/30000 [17:44<52:59,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7500 (1064.51814s): 1.0116395950317383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8002/30000 [18:55<51:26,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8000 (1135.10367s): 0.9385262131690979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8502/30000 [20:05<50:40,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8500 (1205.67418s): 0.9700348377227783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9002/30000 [21:16<49:28,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9000 (1276.32483s): 0.930557131767273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 9502/30000 [22:27<48:16,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9500 (1347.05130s): 0.9374202489852905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10002/30000 [23:38<48:21,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10000 (1418.25959s): 0.9643851518630981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 10502/30000 [24:50<46:13,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10500 (1490.07531s): 0.9492642879486084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11002/30000 [26:01<45:51,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11000 (1561.04584s): 0.9054818153381348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 11502/30000 [27:12<43:48,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11500 (1631.97647s): 0.9225693345069885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12002/30000 [28:23<42:16,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12000 (1702.89901s): 0.9230242371559143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 12502/30000 [29:33<41:57,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12500 (1773.59209s): 0.9109727144241333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13002/30000 [30:44<40:10,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13000 (1844.85536s): 0.8432388305664062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 13502/30000 [31:56<38:58,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13500 (1916.09841s): 0.8858431577682495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14002/30000 [33:07<37:43,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14000 (1987.27144s): 0.8960751295089722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14502/30000 [34:18<36:38,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14500 (2058.20129s): 0.8274625539779663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15002/30000 [35:29<35:26,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15000 (2129.45701s): 0.9176118969917297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 15502/30000 [36:40<34:18,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15500 (2200.77844s): 0.89134281873703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16002/30000 [37:52<33:10,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16000 (2272.04636s): 0.8564547300338745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 16502/30000 [39:03<31:50,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16500 (2343.26157s): 0.8203096389770508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17002/30000 [40:14<31:15,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17000 (2414.51778s): 0.8547755479812622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 17502/30000 [41:25<29:31,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17500 (2485.83381s): 0.8248926997184753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18002/30000 [42:37<28:33,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18000 (2557.13467s): 0.8240297436714172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18502/30000 [43:48<27:10,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18500 (2628.15525s): 0.8590502738952637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19002/30000 [44:59<26:01,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19000 (2698.98448s): 0.8413810729980469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 19502/30000 [46:10<24:59,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19500 (2769.90259s): 0.8830087780952454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20002/30000 [47:21<23:44,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20000 (2841.28588s): 0.8501855134963989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 20502/30000 [48:32<22:46,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20500 (2912.72717s): 0.8488247394561768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21002/30000 [49:44<21:35,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21000 (2984.21906s): 0.8354865908622742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 21502/30000 [50:56<20:18,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21500 (3055.93455s): 0.8228123784065247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22002/30000 [52:07<19:02,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22000 (3127.24859s): 0.8734666109085083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 22502/30000 [53:18<17:58,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22500 (3198.53531s): 0.8536523580551147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23002/30000 [54:30<17:02,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23000 (3270.12337s): 0.7809343338012695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 23502/30000 [55:41<15:24,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23500 (3341.57679s): 0.8509016633033752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24002/30000 [56:53<14:09,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24000 (3413.02210s): 0.8154550194740295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 24502/30000 [58:04<12:59,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24500 (3484.42279s): 0.8397276997566223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25002/30000 [59:15<11:52,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25000 (3555.84041s): 0.8444985747337341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 25502/30000 [1:00:27<10:37,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25500 (3627.22391s): 0.8755136728286743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26002/30000 [1:01:38<09:26,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26000 (3698.38900s): 0.8017162680625916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 26502/30000 [1:02:49<08:14,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26500 (3769.63526s): 0.8414490818977356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27002/30000 [1:04:01<07:09,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27000 (3840.88077s): 0.7843167781829834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 27502/30000 [1:05:12<06:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27500 (3912.06176s): 0.8364068865776062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28002/30000 [1:06:23<04:45,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 28000 (3983.18835s): 0.778032660484314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 28502/30000 [1:07:34<03:32,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 28500 (4054.45079s): 0.8168056011199951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29002/30000 [1:08:45<02:20,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29000 (4125.67949s): 0.7425625920295715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 29502/30000 [1:09:57<01:11,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29500 (4196.96880s): 0.8318692445755005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [1:11:08<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tqdm\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "\n",
    "for steps in tqdm.tqdm(range(30000)):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % eval_interval == 0:\n",
    "        print(f\"Step {steps} ({time.time() - start:.5f}s):\", loss.item())\n",
    "\n",
    "print(\"Done!\")\n",
    "torch.save(model.state_dict(), 'model_weights.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98470dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\twhite the $p\\\\right$ obtainservative $\\\\mathrm{XVBRatS}^c$ is a braid as Hegeland, a quasitopous choose $Y^{\\\\mathrm{op}}$ of [[point-arrows]] is denoted $[S^{\\\\pm}], \\n\\n* which determines the corresponding pullbacks of [[universal projective orbits|universal projective modules]] over $X$ which is denoted by any $\\\\oversetext.\\n\\n### Whatever the universal property\\n\\nThe [[arrow separations are preserved by [[axioms]]] of the [[irreflexive category]]. (However, the Grothendieck-Theoretical orbits is very arguable abstract for detail: \\n\\n$\\\\begin{defin}\\n  \\\\gircoloneqq\\n  \\\\begin{proof}\\n  \\\\array{\\n     F_q \\\\approx{{\\\\elim_{i \\\\phi}}^\\\\deg(\\\\frac{1}{2}\\\\dot ( iu\\\\tor)^p )} j\\n      {\\\\delta( \\\\chi_{n+1}^\\\\ddeg( i \\\\to j \\\\underlying_{\\\\phi}^\\\\deg))$\\n      \\\\\\\\\\n      \\\\end{aligned}\\n     \\\\\\\\\\n    F^n G &\\\\coloneqq& \\\\left\\\\{ i \\\\iota_J, j\\\\right\\\\}_{i,j} J)\\n    \\\\;\\\\coloneqq\\\\;\\n  \\\\Big(\\n     \\\\Sigma_J(U) \\\\big[ I, \\\\chi_i\\n    \\\\Big[ i \\\\tfrac{i}{\\\\phi}}\\\\big)\\n  \\\\Big)\\n  \\\\end{aligned}\\n  \\\\;Big(\\n   \\\\;\\\\;\\n  \\\\Big\\\\;\\n  \\\\underset{i \\\\in \\\\mathbb{N}}{\\\\'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('document.md', 'w', encoding=\"utf-8\") as fd:\n",
    "    fd.write(decode(model.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=2048)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
