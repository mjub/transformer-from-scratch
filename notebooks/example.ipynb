{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5344ee6",
   "metadata": {},
   "source": [
    "# A basic rundown of this repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013db42",
   "metadata": {},
   "source": [
    "We start by loading the base `config.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9765ee5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='nlab-gpt',\n",
       "          seed=1728,\n",
       "          tokenizer='data/tokenizer.json',\n",
       "          special_tokens=['<|startoftext|>', '<|endoftext|>'],\n",
       "          vocab_size=8192,\n",
       "          train_data='data/train_data.pt',\n",
       "          val_data='data/val_data.pt',\n",
       "          max_position_embeddings=512,\n",
       "          hidden_size=256,\n",
       "          intermediate_size=1024,\n",
       "          num_hidden_layers=8,\n",
       "          num_attention_heads=4,\n",
       "          num_key_value_heads=2,\n",
       "          tie_word_embeddings=True,\n",
       "          dropout=0.1,\n",
       "          rms_norm_eps=1e-05,\n",
       "          per_device_train_batch_size=16,\n",
       "          learning_rate=0.0003,\n",
       "          max_steps=40000,\n",
       "          eval_steps=500,\n",
       "          max_eval_samples=50,\n",
       "          runs_dir='runs',\n",
       "          checkpoint_steps=1000)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import types\n",
    "\n",
    "with open(\"../config.json\") as fd:\n",
    "    config = json.load(fd, object_hook=lambda d: types.SimpleNamespace(**d))\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ce23d",
   "metadata": {},
   "source": [
    "We then create a new `Run` and inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d801fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da1c34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Transformer                                   [16, 512, 8192]           --\n",
       "├─Embedding: 1-1                              [16, 512, 256]            2,097,152\n",
       "├─Embedding: 1-2                              [512, 256]                131,072\n",
       "├─Dropout: 1-3                                [16, 512, 256]            --\n",
       "├─ModuleList: 1-4                             --                        --\n",
       "│    └─DecoderLayer: 2-1                      [16, 512, 256]            --\n",
       "│    │    └─RMSNorm: 3-1                      [16, 512, 256]            256\n",
       "│    │    └─GroupedQueryAttention: 3-2        [16, 512, 256]            196,608\n",
       "│    │    └─RMSNorm: 3-3                      [16, 512, 256]            256\n",
       "│    │    └─FeedForward: 3-4                  [16, 512, 256]            524,288\n",
       "│    └─DecoderLayer: 2-2                      [16, 512, 256]            --\n",
       "│    │    └─RMSNorm: 3-5                      [16, 512, 256]            256\n",
       "│    │    └─GroupedQueryAttention: 3-6        [16, 512, 256]            196,608\n",
       "│    │    └─RMSNorm: 3-7                      [16, 512, 256]            256\n",
       "│    │    └─FeedForward: 3-8                  [16, 512, 256]            524,288\n",
       "│    └─DecoderLayer: 2-3                      [16, 512, 256]            --\n",
       "│    │    └─RMSNorm: 3-9                      [16, 512, 256]            256\n",
       "│    │    └─GroupedQueryAttention: 3-10       [16, 512, 256]            196,608\n",
       "│    │    └─RMSNorm: 3-11                     [16, 512, 256]            256\n",
       "│    │    └─FeedForward: 3-12                 [16, 512, 256]            524,288\n",
       "│    └─DecoderLayer: 2-4                      [16, 512, 256]            --\n",
       "│    │    └─RMSNorm: 3-13                     [16, 512, 256]            256\n",
       "│    │    └─GroupedQueryAttention: 3-14       [16, 512, 256]            196,608\n",
       "│    │    └─RMSNorm: 3-15                     [16, 512, 256]            256\n",
       "│    │    └─FeedForward: 3-16                 [16, 512, 256]            524,288\n",
       "│    └─DecoderLayer: 2-5                      [16, 512, 256]            --\n",
       "│    │    └─RMSNorm: 3-17                     [16, 512, 256]            256\n",
       "│    │    └─GroupedQueryAttention: 3-18       [16, 512, 256]            196,608\n",
       "│    │    └─RMSNorm: 3-19                     [16, 512, 256]            256\n",
       "│    │    └─FeedForward: 3-20                 [16, 512, 256]            524,288\n",
       "│    └─DecoderLayer: 2-6                      [16, 512, 256]            --\n",
       "│    │    └─RMSNorm: 3-21                     [16, 512, 256]            256\n",
       "│    │    └─GroupedQueryAttention: 3-22       [16, 512, 256]            196,608\n",
       "│    │    └─RMSNorm: 3-23                     [16, 512, 256]            256\n",
       "│    │    └─FeedForward: 3-24                 [16, 512, 256]            524,288\n",
       "│    └─DecoderLayer: 2-7                      [16, 512, 256]            --\n",
       "│    │    └─RMSNorm: 3-25                     [16, 512, 256]            256\n",
       "│    │    └─GroupedQueryAttention: 3-26       [16, 512, 256]            196,608\n",
       "│    │    └─RMSNorm: 3-27                     [16, 512, 256]            256\n",
       "│    │    └─FeedForward: 3-28                 [16, 512, 256]            524,288\n",
       "│    └─DecoderLayer: 2-8                      [16, 512, 256]            --\n",
       "│    │    └─RMSNorm: 3-29                     [16, 512, 256]            256\n",
       "│    │    └─GroupedQueryAttention: 3-30       [16, 512, 256]            196,608\n",
       "│    │    └─RMSNorm: 3-31                     [16, 512, 256]            256\n",
       "│    │    └─FeedForward: 3-32                 [16, 512, 256]            524,288\n",
       "├─RMSNorm: 1-5                                [16, 512, 256]            256\n",
       "├─Linear: 1-6                                 [16, 512, 8192]           2,097,152\n",
       "===============================================================================================\n",
       "Total params: 10,096,896\n",
       "Trainable params: 10,096,896\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 226.56\n",
       "===============================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 1913.65\n",
       "Params size (MB): 40.39\n",
       "Estimated Total Size (MB): 1954.10\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "run = train.Run(config)\n",
    "\n",
    "run.model.eval()\n",
    "info = torchinfo.summary(\n",
    "    run.model,\n",
    "    input_size=(\n",
    "        run.config.per_device_train_batch_size,\n",
    "        run.config.max_position_embeddings,\n",
    "    ),\n",
    "    dtypes=[torch.long],\n",
    ")\n",
    "run.model.train()\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73917c1f",
   "metadata": {},
   "source": [
    "We create a new `Trainer` for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a378a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train.Trainer at 0x7f1ccef20510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# We disable logging for the notebook\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "# We need to change the data paths relative to the \"notebooks/\" directory\n",
    "run.config.tokenizer = \"../data/tokenizer.json\"\n",
    "run.config.train_data = \"../data/train_data.pt\"\n",
    "run.config.val_data = \"../data/val_data.pt\"\n",
    "\n",
    "# Change the maximum number of steps to something tractable inside the notebook\n",
    "run.config.max_steps = 1000\n",
    "run.config.eval_steps = 1000\n",
    "\n",
    "trainer = train.Trainer(run, device=\"cuda\")\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7805a835",
   "metadata": {},
   "source": [
    "And now we're all set to run the actual training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be7845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b315dbf5eb7848bca8f3d86713bb4ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1000 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(jupyter_notebook=True, no_warmup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9488de",
   "metadata": {},
   "source": [
    "Now let's try our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707df493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import infer\n",
    "\n",
    "\n",
    "def generate_tokens(run, text, tokens=128, tokenizer=None):\n",
    "    print(text, end=\"\", flush=True)\n",
    "    for token in infer.generate(\n",
    "        run.model, text, tokens=tokens, tokenizer=(tokenizer or run.config.tokenizer)\n",
    "    ):\n",
    "        print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b2c7bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simplicial set is be a context of homotopy theory is not to the above in the same in it is a a right is the category of the model theory of the _E: $X$ be a $X$ is a $T$ but $N$.\n",
      "\n",
      "The category of the equivalence of the sense of $X$ is a $x$, $U$ that $K_1$ is a $c_n$ is a $X$ (the $n$ be a morphism is one.\n",
      "\n",
      "\n",
      "The closed $F)$ be a $A$ are the $C$ is a $x}$, such that $X$"
     ]
    }
   ],
   "source": [
    "generate_tokens(trainer.run, \"A simplicial set is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851bb517",
   "metadata": {},
   "source": [
    "Now let's try a checkpoint that was trained for much longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aedaaacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 1.9755235528945922 | Our undertrained model: 4.786942892074585\n"
     ]
    }
   ],
   "source": [
    "best = train.Run.from_file(\n",
    "    \"../runs/nlab-gpt-8.0M-a8525231/nlab-gpt-8.0M-a8525231-39000-best-7.21.pt\"\n",
    ")\n",
    "print(\n",
    "    f\"Best validation loss: {best.best_validation_loss} | Our undertrained model: {run.best_validation_loss}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a03800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simplicial set is a simplicial set that satisfies the Segal condition:\n",
      "\n",
      "* all hom-objects are the morphisms that differ in $A$;\n",
      "\n",
      "* the morphisms are the morphisms of simplicial sets.\n",
      "\n",
      "=--\n",
      "\n",
      "+-- {: .num_remark}\n",
      "###### Remark\n",
      "\n",
      "The intrinsic notion of _simplicial complexes_, def. \\ref{ASimplicialSet}, is a model for a simplicial set object in the model structure on simplicial sets.\n",
      "\n",
      "=--\n",
      "\n",
      "+-- {: .num_remark }\n",
      "###### Remark\n",
      "\n",
      "For $X \\in \\mathbf{H}$ a simplicial set, the simplicial sets $C(\\{X\\})$ are"
     ]
    }
   ],
   "source": [
    "generate_tokens(best, \"A simplicial set is\", tokenizer=\"../data/tokenizer.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
