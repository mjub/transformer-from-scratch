{
    "name": "nlab-gpt-large",

    "seed": 1728,

    "tokenizer_path": "data/tokenizer.json",
    "special_tokens": [
        "<|startoftext|>",
        "<|endoftext|>"
    ],
    "vocab_size": 8192,

    "train_data": "data/train_data.pt",
    "val_data": "data/val_data.pt",

    "max_position_embeddings": 1024,

    "hidden_size": 384,
    "intermediate_size": 1536,
    "num_hidden_layers": 6,
    "num_attention_heads": 8,
    "num_key_value_heads": 4,
    "tie_word_embeddings": true,

    "dropout": 0.1,
    "rms_norm_eps": 1e-5,

    "per_device_train_batch_size": 16,
    "learning_rate": 3e-4,
    "max_steps": 50000,

    "eval_steps": 500,
    "max_eval_samples": 250,

    "runs_dir": "runs",
    "checkpoint_steps": 1000
}
